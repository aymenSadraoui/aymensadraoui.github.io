<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Aymen Sadraoui | AI & Computational Pathology</title>
  <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
  <link rel="stylesheet" href="style.css" />
</head>
<body class="bg-gray-50 text-gray-800 font-sans">
  <div class="max-w-3xl mx-auto p-8">
    <header class="flex flex-col items-center text-center">
      <img src="figures/profile.jpg" alt="Aymen Sadraoui" class="w-32 h-32 rounded-full shadow mb-4">
      <h1 class="text-3xl font-bold mb-2">Aymen Sadraoui</h1>
      <p class="text-lg text-gray-600">PhD in AI & Computational Pathology | Centre de vision num√©rique (CVN)  CentraleSup√©lec, Universit√© Paris-Saclay, France</p>
      <div class="mt-4 space-x-4">
        <a href="https://scholar.google.com/citations?user=OHURXa0AAAAJ&hl=en" target="_blank" class="text-blue-600 hover:underline">Google Scholar</a>
        <a href="https://www.linkedin.com/in/aymen-sadraoui-abb571288/" target="_blank" class="text-blue-600 hover:underline">LinkedIn</a>
        <a href="https://github.com/aymensadraoui" target="_blank" class="text-blue-600 hover:underline">GitHub</a>
      </div>
    </header>

    <main class="mt-10 space-y-8">
      <section id="about">
        <h2 class="text-2xl font-semibold mb-2">About Me</h2>
        <p class="leading-relaxed">
<p class="leading-relaxed">
  I am a PhD student at <b>CentraleSup√©lec, Universit√© Paris-Saclay</b>, conducting my research between the 
  <b>CVN laboratory</b> and the <b>Kremlin-Bic√™tre Hospital</b>. My work focuses on developing 
  <b>AI-based diagnostic and prognostic models</b> for <b>Hepatocellular Carcinoma (HCC)</b> from 
  histopathological whole slide images (WSIs).  
  <br><br>
  On the <b>diagnostic</b> side, I designed deep learning frameworks for the automated detection 
  and classification of tumor architectures, leveraging fully-supervised model at different scales, few-shot models and transductive learning to 
  handle limited labeled data and improve spatial coherence across WSIs.  
  <br><br>
  For the <b>prognostic</b> aspect, my work aims to predict <b>recurrence risk</b> by integrating 
  various AI-based features extracted from WSIs with clinical and macroscopic data. This involves 
  building interpretable models that link visual phenotypes to patient outcomes.  
  <br><br>
  In parallel, I explore <b>convex optimization and algorithm unrolling</b> techniques for 
  <b>stain separation and stain normalization</b> in histopathology. By unrolling proximal 
  algorithms into neural networks, my models achieve more robust color deconvolution and improved stain appearence across histopathological images.
</p>

      </section>

      <section id="publications">
        <h2 class="text-2xl font-semibold mb-2">Publications</h2>
        <ul class="list-disc pl-6 space-y-2">
            <li>
            Zhou, L., Sadraoui, A., <i>et al.</i> (2025). 
            <b>UNEM: UNrolled Generalized EM for Transductive Few-Shot Learning</b>. 
            <i>Computer Vision and Pattern Recognition Conference (CVPR 2025)</i>.
          </li>
          <li>
            Laurent-Bellue, A., Sadraoui, A., <i>et al.</i> (2024). 
            <b>Deep Learning Classification and Quantification of Pejorative and Nonpejorative Architectures in Resected Hepatocellular Carcinoma from Digital Histopathologic Images</b>. 
            <i>The American Journal of Pathology</i>.
          </li>
          <li>
            Sadraoui, A., Martin, S., <i>et al.</i> (2024). 
            <b>A transductive few-shot learning approach for classification of digital histopathological slides from liver cancer</b>. 
            <i>IEEE ISBI 2024</i>.
          </li>
          <li>
            Sadraoui, A., Laurent-Bellue, A., <i>et al.</i> (2024). 
            <b>Unrolled projected gradient algorithm for stain separation in digital histopathological images</b>. 
            <i>IEEE ICIP 2024</i>.
          </li>
        </ul>
      </section>

      <section id="awards">
        <h2 class="text-2xl font-semibold mb-2">Achievements</h2>
        <p>
          üèÜ 1st Place (out of 256 team)‚Äî <b>DigiLut Data Challenge for Lung Transplant Rejection</b> organized by H√¥pital Foch and Bpifrance.  
          Represented CVN, CentraleSup√©lec, Universit√© Paris-Saclay, Inria, and OPIS.
          <a href="https://www.linkedin.com/feed/update/urn:li:activity:7241338279902560256/" target="_blank" class="text-blue-600 hover:underline">DigiLut Data Challenge</a>
        </p>
      </section>
      <section id="contact">
  <h2 class="text-2xl font-semibold mb-2">Contact</h2>
  <p>
    üìß <a href="mailto:aymen.sadraoui@centralesupelec.fr" class="text-blue-600 hover:underline">aymen.sadraoui@centralesupelec.fr</a>
  <p>
    üìß <a href="mailto:aymensadraoui1919@gmail.com" class="text-blue-600 hover:underline"> aymensadraoui1919@gmail.com</a>  
  </p>
        <br>
    üìû +33 (0)7 65 68 52 67<br>
    üìç Centre de Vision Num√©rique, CentraleSup√©lec, Gif-sur-Yvette, 91190, France
  </p>
</section>
    </main>

    <footer class="mt-10 text-center text-gray-500 text-sm">
      ¬© 2025 Aymen Sadraoui.
    </footer>
  </div>
</body>
</html>
